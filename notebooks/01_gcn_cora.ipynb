{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49d0571",
   "metadata": {},
   "source": [
    "# Replicating a Simple GNN on Cora\n",
    "\n",
    "**Goal**: Train a two-layer Graph Convolutional Network for node classification on the Cora ciitation network, then evaluate accuracy and macro-F1.\n",
    "\n",
    "**What we'll learn**:\n",
    "- What a *graph* is in ML terms (nodes, edges, features, labels)\n",
    "- What a *GCN layer* does\n",
    "- How to train, validate, and test a node classifier on a graph "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab638c0e",
   "metadata": {},
   "source": [
    "We import PyTorch (deep learning), PyTorch Geometric (graph tools), and sklearn (metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2e8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time, math, pathlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e318a",
   "metadata": {},
   "source": [
    "## 1. Set seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b457019",
   "metadata": {},
   "source": [
    "Deep learning uses randomness (weigh initialization, shuffling). Fixing seeds makes runs more repeatable. `DEVICE` selects GPU if available; otherwise CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16898593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_seeds(42)\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5154b",
   "metadata": {},
   "source": [
    "## 2. Load Cora & peek at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e1a60",
   "metadata": {},
   "source": [
    "**What is this dataset?**\n",
    "- Nodes = research papers\n",
    "- Edges = citation links (who cites whom)\n",
    "- Features = bag-of-words descriptions of each paper\n",
    "- Label = topic category of each paper\n",
    "\n",
    "We learn a function $$f_\\theta(X,A) \\to \\hat{Y}$$ that uses node features $X$ and graph structure $A$ (adjacency) to predict the **class** $Y$ for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059ed6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "Nodes: 2708\n",
      "Edges (undirected): 5278\n",
      "Node features (dim): 1433\n",
      "Num classes: 7\n",
      "Split sizes (train/val/test): 140 500 1000\n"
     ]
    }
   ],
   "source": [
    "# Dataset root\n",
    "root = str((pathlib.Path.cwd().parent if pathlib.Path.cwd().name==\"notebooks\" else pathlib.Path.cwd()) / \"data\")\n",
    "\n",
    "dataset = Planetoid(root=root, name=\"Cora\")\n",
    "data = dataset[0].to(DEVICE)\n",
    "\n",
    "print(dataset)\n",
    "print(f\"Nodes: {data.num_nodes}\")\n",
    "print(f\"Edges (undirected): {data.num_edges//2}\")\n",
    "print(f\"Node features (dim): {dataset.num_node_features}\")\n",
    "print(f\"Num classes: {dataset.num_classes}\")\n",
    "print(\"Split sizes (train/val/test):\",\n",
    "        int(data.train_mask.sum()),\n",
    "        int(data.val_mask.sum()),\n",
    "        int(data.test_mask.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd28cd7",
   "metadata": {},
   "source": [
    "## 3. Define a minimal GCN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d39689",
   "metadata": {},
   "source": [
    "**What does a GCN layer do?**\n",
    "\n",
    "For each node, it:\n",
    "1. Collects (averages) the representations of its neighbors (including itself),\n",
    "2. Transforms that average using learable weights,\n",
    "3. Applies a nonlinearity (ReLU)\n",
    "\n",
    "**1 Layer Example**:\n",
    "$$\n",
    "H^{(l+1)}=\\sigma\\big(\\hat{D}^{-\\frac{1}{2}}\\hat{A}\\hat{D}^{-\\frac{1}{2}}\\, H^{(l)}W^{(l)}\\big)\n",
    "$$\n",
    "where $\\hat{A}=A+I$ adds self-loops, $\\hat{D}$ is degree matrix, $H^{(0)}=X$ (features). This is a special case of message passing on graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef7f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5, num_layers=2):\n",
    "        super().__init__()\n",
    "        assert num_layers in [2,3], \"For this trial, keep it 2 or 3 layers.\"\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_dim, hidden_dim))\n",
    "        if num_layers == 3:\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        self.convs.append(GCNConv(hidden_dim, out_dim))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)  # message passing + linear transform\n",
    "            if i < len(self.convs) -1: # not on the last layer\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p = self.dropout, training=self.training)\n",
    "        return x # logits (one score per class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954104a",
   "metadata": {},
   "source": [
    "## 4. Training utilities (early stopping on val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f6f3a",
   "metadata": {},
   "source": [
    "We pick the epoch with the **best validation accuracy** to avoid overfitting. Then we evaluate once on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6b4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainCfg:\n",
    "    hidden_dim: int = 64\n",
    "    lr: float = 0.01\n",
    "    weight_decay: float = 5e-4\n",
    "    dropout: float = 0.5\n",
    "    num_layers: int = 2\n",
    "    max_epochs: int = 500\n",
    "    patience: int = 50 # stop if val accuracy doesn't improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "674566d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_logits(logits, y, mask):\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    return (pred[mask]==y[mask]).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5590543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(cfg: TrainCfg, data):\n",
    "    set_seeds(42)\n",
    "    model = GCN(\n",
    "        in_dim = data.num_node_features,\n",
    "        hidden_dim = cfg.hidden_dim,\n",
    "        out_dim = int(data.y.max().item()) + 1,\n",
    "        dropout=cfg.dropout,\n",
    "        num_layers = cfg.num_layers\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_state = None\n",
    "    bad_epochs = 0\n",
    "\n",
    "    for epoch in range(1, cfg.max_epochs + 1):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(logits[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(data.x, data.edge_index)\n",
    "            train_acc = accuracy_from_logits(logits, data.y, data.train_mask)\n",
    "            val_acc = accuracy_from_logits(logits, data.y, data.val_mask)\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad_epochs = 0\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        if epoch % 25 ==0 or epoch == 1:\n",
    "            print(f\"epoch {epoch:3d} | loss {loss.item():.4f} | train {train_acc:.3f} | val {val_acc:.3f}\")\n",
    "\n",
    "        if bad_epochs >= cfg.patience:\n",
    "            # early stopping\n",
    "            break\n",
    "        \n",
    "    # load best checkpoint\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
    "\n",
    "    return model, best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ce266",
   "metadata": {},
   "source": [
    "## 5. Train baseline GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2188099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1 | loss 1.9582 | train 0.836 | val 0.466\n",
      "epoch  25 | loss 0.0104 | train 1.000 | val 0.784\n",
      "epoch  50 | loss 0.0104 | train 1.000 | val 0.778\n",
      "epoch  75 | loss 0.0150 | train 1.000 | val 0.778\n",
      "epoch 100 | loss 0.0137 | train 1.000 | val 0.774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7919999957084656"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = TrainCfg()\n",
    "model, best_val = train_one(cfg, data)\n",
    "best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc5333",
   "metadata": {},
   "source": [
    "The printed value is our best validation accuracy. We only use this to select the model. Next we'll test it once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a2907",
   "metadata": {},
   "source": [
    "## 6. Evaluate on the test split (accuracy + macro f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cc80e",
   "metadata": {},
   "source": [
    "Why macro-f1 as well as accuracy?\n",
    "\n",
    "If classes are imbalanced, accuracy can be misleading. Macro f1 averages F1 over classes equally, giving minority classes fair weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f7580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        yhat = logits.argmax(dim=-1).cpu().numpy()\n",
    "        y = data.y.cpu().numpy()\n",
    "        test = data.test_mask.cpu().numpy().astype(bool)\n",
    "        acc = (yhat[test] == y[test]).mean()\n",
    "        macro = f1_score(y[test], yhat[test], average = \"macro\")\n",
    "    return {\"test_acc\": acc, \"test_macro_f1\": macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f932296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_acc': np.float64(0.809), 'test_macro_f1': 0.7980508036746983}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = evaluate(model, data)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ab310",
   "metadata": {},
   "source": [
    "## 7. Hidden size, layers, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4bb92bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1 | loss 1.9444 | train 0.571 | val 0.366\n",
      "epoch  25 | loss 0.0701 | train 1.000 | val 0.764\n",
      "epoch  50 | loss 0.0154 | train 1.000 | val 0.778\n",
      "epoch  75 | loss 0.0176 | train 1.000 | val 0.784\n",
      "epoch 100 | loss 0.0165 | train 1.000 | val 0.778\n",
      "{'hidden': 16, 'layers': 2, 'dropout': 0.0, 'best_val_acc': 0.7839999794960022, 'test_acc': np.float64(0.803), 'test_macro_f1': 0.7975079547315848}\n",
      "epoch   1 | loss 1.9524 | train 0.514 | val 0.354\n",
      "epoch  25 | loss 0.1844 | train 1.000 | val 0.780\n",
      "epoch  50 | loss 0.0433 | train 1.000 | val 0.766\n",
      "epoch  75 | loss 0.0368 | train 1.000 | val 0.768\n",
      "epoch 100 | loss 0.0427 | train 1.000 | val 0.776\n",
      "{'hidden': 16, 'layers': 2, 'dropout': 0.5, 'best_val_acc': 0.7839999794960022, 'test_acc': np.float64(0.806), 'test_macro_f1': 0.7989440094679472}\n",
      "epoch   1 | loss 1.9459 | train 0.364 | val 0.252\n",
      "epoch  25 | loss 0.0328 | train 1.000 | val 0.770\n",
      "epoch  50 | loss 0.0043 | train 1.000 | val 0.768\n",
      "{'hidden': 16, 'layers': 3, 'dropout': 0.0, 'best_val_acc': 0.7820000052452087, 'test_acc': np.float64(0.774), 'test_macro_f1': 0.7641612510672104}\n",
      "epoch   1 | loss 1.9486 | train 0.393 | val 0.310\n",
      "epoch  25 | loss 0.3232 | train 0.993 | val 0.774\n",
      "epoch  50 | loss 0.0825 | train 1.000 | val 0.786\n",
      "epoch  75 | loss 0.0490 | train 1.000 | val 0.766\n",
      "{'hidden': 16, 'layers': 3, 'dropout': 0.5, 'best_val_acc': 0.7879999876022339, 'test_acc': np.float64(0.795), 'test_macro_f1': 0.7871319578349233}\n",
      "epoch   1 | loss 1.9512 | train 0.943 | val 0.564\n",
      "epoch  25 | loss 0.0034 | train 1.000 | val 0.792\n",
      "epoch  50 | loss 0.0090 | train 1.000 | val 0.794\n",
      "epoch  75 | loss 0.0109 | train 1.000 | val 0.780\n",
      "epoch 100 | loss 0.0096 | train 1.000 | val 0.774\n",
      "{'hidden': 64, 'layers': 2, 'dropout': 0.0, 'best_val_acc': 0.800000011920929, 'test_acc': np.float64(0.813), 'test_macro_f1': 0.8045253656439473}\n",
      "epoch   1 | loss 1.9582 | train 0.836 | val 0.466\n",
      "epoch  25 | loss 0.0104 | train 1.000 | val 0.784\n",
      "epoch  50 | loss 0.0104 | train 1.000 | val 0.778\n",
      "epoch  75 | loss 0.0150 | train 1.000 | val 0.778\n",
      "epoch 100 | loss 0.0137 | train 1.000 | val 0.774\n",
      "{'hidden': 64, 'layers': 2, 'dropout': 0.5, 'best_val_acc': 0.7919999957084656, 'test_acc': np.float64(0.809), 'test_macro_f1': 0.7980508036746983}\n",
      "epoch   1 | loss 1.9532 | train 0.736 | val 0.502\n",
      "epoch  25 | loss 0.0002 | train 1.000 | val 0.762\n",
      "epoch  50 | loss 0.0017 | train 1.000 | val 0.774\n",
      "{'hidden': 64, 'layers': 3, 'dropout': 0.0, 'best_val_acc': 0.8080000281333923, 'test_acc': np.float64(0.816), 'test_macro_f1': 0.8067946705007782}\n",
      "epoch   1 | loss 1.9555 | train 0.750 | val 0.506\n",
      "epoch  25 | loss 0.0051 | train 1.000 | val 0.782\n",
      "epoch  50 | loss 0.0054 | train 1.000 | val 0.770\n",
      "{'hidden': 64, 'layers': 3, 'dropout': 0.5, 'best_val_acc': 0.800000011920929, 'test_acc': np.float64(0.812), 'test_macro_f1': 0.8048199246936917}\n",
      "epoch   1 | loss 1.9440 | train 0.979 | val 0.700\n",
      "epoch  25 | loss 0.0015 | train 1.000 | val 0.772\n",
      "epoch  50 | loss 0.0104 | train 1.000 | val 0.772\n",
      "{'hidden': 128, 'layers': 2, 'dropout': 0.0, 'best_val_acc': 0.7839999794960022, 'test_acc': np.float64(0.791), 'test_macro_f1': 0.7887109972112798}\n",
      "epoch   1 | loss 1.9467 | train 0.964 | val 0.682\n",
      "epoch  25 | loss 0.0025 | train 1.000 | val 0.776\n",
      "epoch  50 | loss 0.0117 | train 1.000 | val 0.780\n",
      "{'hidden': 128, 'layers': 2, 'dropout': 0.5, 'best_val_acc': 0.7860000133514404, 'test_acc': np.float64(0.803), 'test_macro_f1': 0.7980305602510678}\n",
      "epoch   1 | loss 1.9488 | train 0.779 | val 0.492\n",
      "epoch  25 | loss 0.0002 | train 1.000 | val 0.752\n",
      "epoch  50 | loss 0.0025 | train 1.000 | val 0.770\n",
      "{'hidden': 128, 'layers': 3, 'dropout': 0.0, 'best_val_acc': 0.7879999876022339, 'test_acc': np.float64(0.79), 'test_macro_f1': 0.7867570014056052}\n",
      "epoch   1 | loss 1.9490 | train 0.679 | val 0.456\n",
      "epoch  25 | loss 0.0015 | train 0.993 | val 0.752\n",
      "epoch  50 | loss 0.0058 | train 1.000 | val 0.762\n",
      "{'hidden': 128, 'layers': 3, 'dropout': 0.5, 'best_val_acc': 0.7979999780654907, 'test_acc': np.float64(0.811), 'test_macro_f1': 0.8067062886350023}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for hidden in [16, 64, 128]:\n",
    "    for layers in [2, 3]:\n",
    "        for drop in [0.0, 0.5]:\n",
    "            cfg = TrainCfg(hidden_dim = hidden, num_layers = layers, dropout=drop)\n",
    "            model, best_val=train_one(cfg, data)\n",
    "            m = evaluate(model, data)\n",
    "            rows.append({\n",
    "                \"hidden\": hidden,\n",
    "                \"layers\": layers,\n",
    "                \"dropout\": drop,\n",
    "                \"best_val_acc\": best_val,\n",
    "                \"test_acc\": m[\"test_acc\"],\n",
    "                \"test_macro_f1\": m[\"test_macro_f1\"],\n",
    "            })\n",
    "            print(rows[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933676c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.806795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.804525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.804820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.806706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.798051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.798944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.797508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.798031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.787132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.786757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.764161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden  layers  dropout  best_val_acc  test_acc  test_macro_f1\n",
       "0       64       3      0.0         0.808     0.816       0.806795\n",
       "1       64       2      0.0         0.800     0.813       0.804525\n",
       "2       64       3      0.5         0.800     0.812       0.804820\n",
       "3      128       3      0.5         0.798     0.811       0.806706\n",
       "4       64       2      0.5         0.792     0.809       0.798051\n",
       "5       16       2      0.5         0.784     0.806       0.798944\n",
       "6       16       2      0.0         0.784     0.803       0.797508\n",
       "7      128       2      0.5         0.786     0.803       0.798031\n",
       "8       16       3      0.5         0.788     0.795       0.787132\n",
       "9      128       2      0.0         0.784     0.791       0.788711\n",
       "10     128       3      0.0         0.788     0.790       0.786757\n",
       "11      16       3      0.0         0.782     0.774       0.764161"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_df = pd.DataFrame(rows).sort_values(\"test_acc\", ascending=False).reset_index(drop=True)\n",
    "ablation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce98725",
   "metadata": {},
   "source": [
    "**What to look for:**\n",
    "- Hidden size: too small -> underfit; too large -> overfit\n",
    "- Layers: deeper captures wider neighborhoods but may over-smoothing (node embeddings become too similar)\n",
    "- Dropout: helps regularize on small graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e47374",
   "metadata": {},
   "source": [
    "## 8. Compare to non-graph baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7337fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = data.x.cpu().numpy()\n",
    "y = data.y.cpu().numpy()\n",
    "\n",
    "train = data.train_mask.cpu().numpy().astype(bool)\n",
    "test = data.test_mask.cpu().numpy().astype(bool)\n",
    "\n",
    "def eval_sklearn(clf):\n",
    "    clf.fit(X[train], y[train])\n",
    "    yhat = clf.predict(X[test])\n",
    "    return {\n",
    "        \"test_acc\" : (yhat==y[test]).mean(),\n",
    "        \"test_macro_f1\": f1_score(y[test], yhat, average=\"macro\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e195bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics = eval_sklearn(LogisticRegression(max_iter=1000, n_jobs = -1))\n",
    "mlp_metrics = eval_sklearn(MLPClassifier(hidden_layer_sizes = (64,), max_iter = 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a1c2157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': {'test_acc': np.float64(0.576), 'test_macro_f1': 0.5642682651914728},\n",
       " 'MLP': {'test_acc': np.float64(0.506), 'test_macro_f1': 0.5006138950843172},\n",
       " 'GCN': {'test_acc': np.float64(0.809), 'test_macro_f1': 0.7980508036746983}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"LR\":lr_metrics, \"MLP\": mlp_metrics, \"GCN\": metrics}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
